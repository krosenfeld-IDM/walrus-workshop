{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3bae091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rich import print\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from dataclasses import dataclass\n",
    "from alive_progress import alive_it\n",
    "from sortedcontainers import SortedList\n",
    "\n",
    "from walrus_workshop.utils import get_key_value_from_string\n",
    "from walrus_workshop.walrus import get_trajectory\n",
    "from walrus_workshop.model import load_sae\n",
    "from walrus_workshop.metrics import coarsen_field, compute_enstrophy, compute_deformation\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1df11d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config\n",
    "cfg = OmegaConf.load(\"configs/train.yaml\")\n",
    "\n",
    "# Load the trajectory\n",
    "trajectory_id = 50 # 56 also interesting\n",
    "trajectory, trajectory_metadata = get_trajectory(cfg.walrus.dataset, trajectory_id)\n",
    "\n",
    "# Load file list of the activations\n",
    "activations_dir = (\n",
    "    Path(\"activations\")\n",
    "    / \"test\"\n",
    "    / \"blocks.20.space_mixing.activation\"\n",
    "    / cfg.walrus.dataset\n",
    ")\n",
    "act_files = sorted(glob.glob(str(activations_dir / f\"*_traj_{trajectory_id}*\")))\n",
    "# List of steps with activations (starting step)\n",
    "steps = np.array([int(get_key_value_from_string(file_name, \"step\")) for file_name in act_files])\n",
    "\n",
    "# Load the trained SAE\n",
    "checkpoint_path = (\n",
    "    Path(\"checkpoints\")\n",
    "    / \"sae_checkpoint_blocks.20.space_mixing.activation_source_test_k_active=32_k_aux=2048_latent=22528_beta=0.1.pt\"\n",
    ")\n",
    "sae_model, sae_config = load_sae(checkpoint_path)\n",
    "sae_model = sae_model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1372383",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataChunk:\n",
    "    step: int\n",
    "    n_neurons: int\n",
    "    n_features: int\n",
    "    n_timesteps: int\n",
    "    simulation: np.ndarray\n",
    "    neurons: np.ndarray\n",
    "    code: np.ndarray\n",
    "    target: np.ndarray\n",
    "\n",
    "def get_data_chunk(step, step_index, act_files, trajectory, cfg, sae_model, device, verbose=False, target='tke'):\n",
    "\n",
    "    # Get SAE features\n",
    "    if verbose:\n",
    "        print(f\"Opening activation file {Path(act_files[step_index]).stem}\")\n",
    "    assert get_key_value_from_string(Path(act_files[step_index]).stem, \"step\") == step # make sure we are processing the same step\n",
    "    act = zarr.open(act_files[step_index], mode=\"r\")\n",
    "    act = torch.from_numpy(np.array(act)).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, code, _ = sae_model(act)\n",
    "    code = code.cpu().numpy()\n",
    "\n",
    "    # Get simulation chunk\n",
    "    simulation_chunk = trajectory['input_fields'][0, step:step+cfg.walrus.n_steps_input, :, :, 0, :]\n",
    "    if verbose:\n",
    "        print(f\"Simulation chunk shape: {simulation_chunk.shape}\")\n",
    "\n",
    "    scale_x = int(simulation_chunk.shape[2] / 32)  # width\n",
    "    scale_y = int(simulation_chunk.shape[1] / 32)  # height\n",
    "\n",
    "    target_index_dict = {'u':2, 'v':3}\n",
    "    target_field = np.zeros((simulation_chunk.shape[0], 32, 32)) # 32 x 32 \n",
    "    for i in range(simulation_chunk.shape[0]):\n",
    "        target_field[i]  = coarsen_field(simulation_chunk[i, ..., target_index_dict[target]], (32, 32), method='mean')\n",
    "\n",
    "    # target_index_dict = {'tau_xx': 0, 'tau_yy': 1, 'tau_xy': 2, 'tke': 3}\n",
    "    # target_field = np.zeros((simulation_chunk.shape[0], 32, 32)) # 32 x 32 \n",
    "    # for i in range(simulation_chunk.shape[0]):\n",
    "    #     target_field[i] = subgrid_stress(simulation_chunk[i, ..., 1], simulation_chunk[i, ..., 2], (32, 32))[target_index_dict[target]]\n",
    "\n",
    "    data_chunk = DataChunk(step=step, n_neurons=act.shape[1], n_features=code.shape[1], n_timesteps=1, simulation=simulation_chunk[-1], neurons=act.cpu().numpy().reshape(6, 32, 32, -1)[-1], code=code.reshape(6, 32, 32, -1)[-1], target=target_field[-1])\n",
    "    return data_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "948ebc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|████████████████████████████████████████| 34/34 [100%] in 17.2s (1.95/s)       \n"
     ]
    }
   ],
   "source": [
    "step_index = 0\n",
    "for step_index in alive_it(range(len(steps)), force_tty=True):\n",
    "    ix, iy = (16, 16) # grid point\n",
    "    step = steps[step_index]\n",
    "    data_chunk = get_data_chunk(step, step_index, act_files, trajectory, cfg, sae_model, device, verbose=False, target='u')\n",
    "    if step_index == 0:\n",
    "        X = np.zeros((len(steps), data_chunk.n_neurons))\n",
    "        y = np.zeros(len(steps))\n",
    "    X[step_index] = data_chunk.neurons[iy, ix, :]\n",
    "    y[step_index] = data_chunk.target[iy, ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fa6f957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2816</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span>,<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m34\u001b[0m, \u001b[1;36m2816\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m(\u001b[0m\u001b[1;36m34\u001b[0m,\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Ridge R² <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>-fold<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-9.9435</span> ± <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.1081</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Ridge R² \u001b[1m(\u001b[0m\u001b[1;36m5\u001b[0m-fold\u001b[1m)\u001b[0m: \u001b[1;36m-9.9435\u001b[0m ± \u001b[1;36m8.1081\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X.shape, y.shape)\n",
    "r = Ridge(alpha=100)\n",
    "model = r.fit(X, y)\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(f\"Ridge R² (5-fold): {scores.mean():.4f} ± {scores.std():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
