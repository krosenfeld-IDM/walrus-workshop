# Training configuration for SAE model

# Model architecture parameters
model:
  expansion_factor: 8  # Multiplier for latent dimension (latent = d_in * expansion_factor)
  k_active: 32  # Number of active neurons
  k_aux: 512  # Number of auxiliary neurons
  dead_window: 5_000_000  # Window for dead neuron tracking

# Training hyperparameters
training:
  split: "train"
  batch_size: 8192
  learning_rate: 0.0003  # 3e-4
  epochs: 5
  source_split: "test"
  save_every: "epoch"

# Wandb configuration
wandb:
  use_wandb: true
  wandb_project: "walrus-workshop"  # Base project name (can be overridden with layer_name)
  wandb_run_name: null  # null will auto-generate a name

# Walrus-specific settings (for train_walrus)
walrus:
  dataset: "shear_flow"
  num_workers: 4
  random_state: 42  # For train/test split
