# Training configuration for SAE model

# Model architecture parameters
model:
  latent: 3072  # Latent dimension (d_in * 4 by default, can be d_in * expansion_factor)
  expansion_factor: 32  # Multiplier for latent dimension (latent = d_in * expansion_factor)
  k_active: 128  # Number of active neurons
  k_aux: 512  # Number of auxiliary neurons
  dead_window: 500_000  # Window for dead neuron tracking

# Training hyperparameters
training:
  split: "train"
  batch_size: 1024
  learning_rate: 0.0003  # 3e-4
  epochs: 5
  source_split: "test"
  save_every: "epoch"

# Wandb configuration
wandb:
  use_wandb: true
  wandb_project: "walrus-workshop"  # Base project name (can be overridden with layer_name)
  wandb_run_name: null  # null will auto-generate a name

# Demo-specific settings (for train_demo)
demo:
  num_arrays: 5
  samples_per_array: 10000

# Walrus-specific settings (for train_walrus)
walrus:
  dataset: "shear_flow"
  num_workers: 4
  random_state: 42  # For train/test split
